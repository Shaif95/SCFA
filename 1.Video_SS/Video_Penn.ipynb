{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5419b8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import collections\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import shutil\n",
    "import keras\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import keras\n",
    "import json\n",
    "import tensorflow as tf \n",
    "from keras.layers import Input\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, LSTM,Flatten, TimeDistributed, Conv2D, Dropout\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D,Reshape, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten, UpSampling2D\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "\n",
    "def get_f1(y_true, y_pred): #taken from old keras source code\n",
    "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    \n",
    "    tn = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    fp = K.sum(K.round(K.clip((1-y_true) * (y_pred), 0, 1)))\n",
    "    fn = K.sum(K.round(K.clip((y_true) * (1-y_pred), 0, 1)))\n",
    "    \n",
    "\n",
    "    f1_val = tp / ( tp + ( (1/2) * (fp+fn) ) + K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d2239d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GPU is available.\n",
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# List all physical GPUs\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    print(\"✅ GPU is available.\")\n",
    "    for gpu in gpus:\n",
    "        print(gpu)\n",
    "else:\n",
    "    print(\"❌ No GPU found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fca053a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "trn=r'D:/D-Video/hmdb/*/'\n",
    "tr= glob(trn)\n",
    "len(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "273abbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "val = []\n",
    "test = []\n",
    "train_y = []\n",
    "val_y = []\n",
    "test_y = []\n",
    "\n",
    "y = 0\n",
    "for i in tr:\n",
    "    \n",
    "    #print(i)\n",
    "    x = glob(i+'/*/')\n",
    "    \n",
    "    #shuffle(x)\n",
    "    t,tt = train_test_split( x , test_size=0.1, random_state=42)\n",
    "    t, vv = train_test_split( t , test_size=0.1, random_state=42)\n",
    "    \n",
    "    for j in t:\n",
    "        \n",
    "        mm = len(glob(j+'/*'))\n",
    "        \n",
    "        if(mm<10):\n",
    "            continue\n",
    "        \n",
    "        train.append(j)\n",
    "        train_y.append(y)\n",
    "    \n",
    "    for j in vv:\n",
    "        \n",
    "        mm = len(glob(j+'/*'))\n",
    "        \n",
    "        if(mm<10):\n",
    "            continue\n",
    "            \n",
    "        val.append(j)\n",
    "        val_y.append(y)\n",
    "        \n",
    "    for j in tt:\n",
    "        \n",
    "        mm = len(glob(j+'/*'))\n",
    "        \n",
    "        if(mm<10):\n",
    "            continue\n",
    "            \n",
    "        test.append(j)\n",
    "        test_y.append(y)\n",
    "        \n",
    "    y = y+1\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "tra_y =  np.array(to_categorical(train_y))\n",
    "va_y  =  np.array(to_categorical(val_y))\n",
    "te_y  =  np.array(to_categorical(test_y))\n",
    "\n",
    "(train, tra_y) = shuffle(train, tra_y)\n",
    "(val, va_y) = shuffle(val, va_y)\n",
    "(test, te_y) = shuffle(test, te_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edb552fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639495b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "798d6e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_te(k , a) :\n",
    "    x = glob(k+'/*')\n",
    "    imgdata=[]\n",
    "    for i in range(0,15):\n",
    "        \n",
    "        a = Image.open(x[i])\n",
    "        b = a.resize((48, 48))\n",
    "        c = np.array(b)\n",
    "        imgdata.append(c.reshape(48, 48,3))\n",
    "        \n",
    "    idata = np.array(imgdata)\n",
    "    X_train = idata\n",
    "    X_train = X_train.astype('float32') / 255.\n",
    "    #print(np.shape(X_train))\n",
    "    return X_train\n",
    "\n",
    "def get_cat(k) :\n",
    "    return np.array(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e352d2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_Custom_Generator(keras.utils.Sequence) :\n",
    "  \n",
    "  def __init__(self, filename , labels, batch_size) :\n",
    "    self.filename = filename\n",
    "    self.labels = labels\n",
    "    self.batch_size = batch_size\n",
    "    \n",
    "    \n",
    "  def __len__(self) :\n",
    "    return (np.ceil(len(self.filename) / float(self.batch_size))).astype(int)\n",
    "  \n",
    "  \n",
    "  def __getitem__(self, idx) :\n",
    "    batch_x = self.filename[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "    batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "    y_train = get_cat(batch_y)\n",
    "    i=0\n",
    "    return np.array([get_te(i,self.filename)for i in batch_x]), np.array( y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b004fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_Test_Generator(keras.utils.Sequence) :\n",
    "  \n",
    "  def __init__(self, filename , batch_size) :\n",
    "    self.filename = filename\n",
    "    self.batch_size = batch_size\n",
    "    \n",
    "    \n",
    "  def __len__(self) :\n",
    "    return (np.ceil(len(self.filename) / float(self.batch_size))).astype(int)\n",
    "  \n",
    "  \n",
    "  def __getitem__(self, idx) :\n",
    "    batch_x = self.filename[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "    i=0\n",
    "    return np.array([get_te(i,self.filename)for i in batch_x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28523f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "my_training_batch_generator = My_Custom_Generator(train, tra_y, batch_size)\n",
    "my_validation_batch_generator = My_Custom_Generator(val, va_y, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bded865c",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(My_Test_Generator(test, batch_size).__getitem__(1))\n",
    "for i in range(2,len(x)):\n",
    "    x = My_Test_Generator(test, batch_size).__getitem__(i)\n",
    "    arr = np.concatenate((arr,x),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffe4a3c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 15, 48, 48, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d616e33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3eb0f671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed_9 (TimeDis  (None, 15, 46, 46, 64)   1792      \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_10 (TimeDi  (None, 15, 23, 23, 64)   0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_11 (TimeDi  (None, 15, 21, 21, 32)   18464     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_12 (TimeDi  (None, 15, 10, 10, 32)   0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_13 (TimeDi  (None, 15, 8, 8, 16)     4624      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_14 (TimeDi  (None, 15, 4, 4, 16)     0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_15 (TimeDi  (None, 15, 2, 2, 8)      1160      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_16 (TimeDi  (None, 15, 1, 1, 8)      0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_17 (TimeDi  (None, 15, 8)            0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 50)                11800     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 51)                2601      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,441\n",
      "Trainable params: 40,441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import TimeDistributed, Conv2D, MaxPooling2D, Flatten, LSTM, Dense\n",
    "\n",
    "num_frames = 15\n",
    "frame_height = 48\n",
    "frame_width = 48\n",
    "num_channels = 3\n",
    "num_classes = 51  # Change this to the number of classes in your dataset\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# CNN\n",
    "model.add(TimeDistributed(Conv2D(64, (3, 3), activation='relu'), input_shape=(num_frames, frame_height, frame_width, num_channels)))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "model.add(TimeDistributed(Conv2D(32, (3, 3), activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "model.add(TimeDistributed(Conv2D(16, (3, 3), activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "model.add(TimeDistributed(Conv2D(8, (3, 3), activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "# LSTM\n",
    "model.add(LSTM(50))\n",
    "\n",
    "# Fully connected layer\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "81e2a065",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67fd3368",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\AppData\\Local\\Temp\\ipykernel_14300\\1958852391.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(generator=my_training_batch_generator, epochs = 50,validation_data = my_validation_batch_generator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "339/339 [==============================] - 1874s 5s/step - loss: 3.8649 - accuracy: 0.0784 - val_loss: 3.7896 - val_accuracy: 0.0775\n",
      "Epoch 2/50\n",
      "339/339 [==============================] - 455s 1s/step - loss: 3.7192 - accuracy: 0.0790 - val_loss: 3.6879 - val_accuracy: 0.0902\n",
      "Epoch 3/50\n",
      "339/339 [==============================] - 458s 1s/step - loss: 3.6366 - accuracy: 0.0901 - val_loss: 3.6451 - val_accuracy: 0.0791\n",
      "Epoch 4/50\n",
      "339/339 [==============================] - 459s 1s/step - loss: 3.5677 - accuracy: 0.0960 - val_loss: 3.5769 - val_accuracy: 0.0918\n",
      "Epoch 5/50\n",
      "339/339 [==============================] - 452s 1s/step - loss: 3.5193 - accuracy: 0.1011 - val_loss: 3.5286 - val_accuracy: 0.0981\n",
      "Epoch 6/50\n",
      "339/339 [==============================] - 489s 1s/step - loss: 3.4653 - accuracy: 0.1096 - val_loss: 3.5261 - val_accuracy: 0.1013\n",
      "Epoch 7/50\n",
      "339/339 [==============================] - 502s 1s/step - loss: 3.4274 - accuracy: 0.1144 - val_loss: 3.4984 - val_accuracy: 0.0934\n",
      "Epoch 8/50\n",
      "339/339 [==============================] - 428s 1s/step - loss: 3.3924 - accuracy: 0.1196 - val_loss: 3.4427 - val_accuracy: 0.1092\n",
      "Epoch 9/50\n",
      "339/339 [==============================] - 486s 1s/step - loss: 3.3409 - accuracy: 0.1238 - val_loss: 3.4026 - val_accuracy: 0.1282\n",
      "Epoch 10/50\n",
      "339/339 [==============================] - 475s 1s/step - loss: 3.3147 - accuracy: 0.1290 - val_loss: 3.3947 - val_accuracy: 0.1092\n",
      "Epoch 11/50\n",
      "339/339 [==============================] - 483s 1s/step - loss: 3.2579 - accuracy: 0.1362 - val_loss: 3.3680 - val_accuracy: 0.1297\n",
      "Epoch 12/50\n",
      "339/339 [==============================] - 453s 1s/step - loss: 3.2324 - accuracy: 0.1405 - val_loss: 3.3652 - val_accuracy: 0.1266\n",
      "Epoch 13/50\n",
      "339/339 [==============================] - 480s 1s/step - loss: 3.2017 - accuracy: 0.1447 - val_loss: 3.3322 - val_accuracy: 0.1487\n",
      "Epoch 14/50\n",
      "339/339 [==============================] - 486s 1s/step - loss: 3.1662 - accuracy: 0.1532 - val_loss: 3.3463 - val_accuracy: 0.1345\n",
      "Epoch 15/50\n",
      "339/339 [==============================] - 479s 1s/step - loss: 3.1401 - accuracy: 0.1573 - val_loss: 3.3153 - val_accuracy: 0.1392\n",
      "Epoch 16/50\n",
      "339/339 [==============================] - 430s 1s/step - loss: 3.1141 - accuracy: 0.1617 - val_loss: 3.3122 - val_accuracy: 0.1487\n",
      "Epoch 17/50\n",
      "339/339 [==============================] - 480s 1s/step - loss: 3.0811 - accuracy: 0.1700 - val_loss: 3.3180 - val_accuracy: 0.1329\n",
      "Epoch 18/50\n",
      "339/339 [==============================] - 462s 1s/step - loss: 3.0570 - accuracy: 0.1757 - val_loss: 3.2957 - val_accuracy: 0.1408\n",
      "Epoch 19/50\n",
      "339/339 [==============================] - 449s 1s/step - loss: 3.0320 - accuracy: 0.1759 - val_loss: 3.3426 - val_accuracy: 0.1297\n",
      "Epoch 20/50\n",
      "339/339 [==============================] - 493s 1s/step - loss: 3.0096 - accuracy: 0.1814 - val_loss: 3.2935 - val_accuracy: 0.1392\n",
      "Epoch 21/50\n",
      "339/339 [==============================] - 503s 1s/step - loss: 2.9717 - accuracy: 0.1925 - val_loss: 3.2714 - val_accuracy: 0.1377\n",
      "Epoch 22/50\n",
      "339/339 [==============================] - 490s 1s/step - loss: 2.9414 - accuracy: 0.1990 - val_loss: 3.2922 - val_accuracy: 0.1424\n",
      "Epoch 23/50\n",
      "339/339 [==============================] - 434s 1s/step - loss: 2.9221 - accuracy: 0.2078 - val_loss: 3.2902 - val_accuracy: 0.1424\n",
      "Epoch 24/50\n",
      "339/339 [==============================] - 452s 1s/step - loss: 2.9089 - accuracy: 0.2065 - val_loss: 3.2683 - val_accuracy: 0.1424\n",
      "Epoch 25/50\n",
      "339/339 [==============================] - 480s 1s/step - loss: 2.8491 - accuracy: 0.2193 - val_loss: 3.3016 - val_accuracy: 0.1408\n",
      "Epoch 26/50\n",
      "339/339 [==============================] - 445s 1s/step - loss: 2.8245 - accuracy: 0.2278 - val_loss: 3.3011 - val_accuracy: 0.1487\n",
      "Epoch 27/50\n",
      "339/339 [==============================] - 482s 1s/step - loss: 2.7969 - accuracy: 0.2291 - val_loss: 3.3044 - val_accuracy: 0.1472\n",
      "Epoch 28/50\n",
      "339/339 [==============================] - 483s 1s/step - loss: 2.7738 - accuracy: 0.2377 - val_loss: 3.3058 - val_accuracy: 0.1503\n",
      "Epoch 29/50\n",
      "339/339 [==============================] - 496s 1s/step - loss: 2.7493 - accuracy: 0.2407 - val_loss: 3.2926 - val_accuracy: 0.1282\n",
      "Epoch 30/50\n",
      "339/339 [==============================] - 484s 1s/step - loss: 2.7315 - accuracy: 0.2436 - val_loss: 3.2937 - val_accuracy: 0.1598\n",
      "Epoch 31/50\n",
      "339/339 [==============================] - 478s 1s/step - loss: 2.7283 - accuracy: 0.2460 - val_loss: 3.2908 - val_accuracy: 0.1440\n",
      "Epoch 32/50\n",
      "339/339 [==============================] - 456s 1s/step - loss: 2.6837 - accuracy: 0.2566 - val_loss: 3.2580 - val_accuracy: 0.1551\n",
      "Epoch 33/50\n",
      "339/339 [==============================] - 478s 1s/step - loss: 2.6364 - accuracy: 0.2698 - val_loss: 3.2955 - val_accuracy: 0.1630\n",
      "Epoch 34/50\n",
      "339/339 [==============================] - 449s 1s/step - loss: 2.6130 - accuracy: 0.2750 - val_loss: 3.2849 - val_accuracy: 0.1725\n",
      "Epoch 35/50\n",
      "339/339 [==============================] - 464s 1s/step - loss: 2.5910 - accuracy: 0.2800 - val_loss: 3.3042 - val_accuracy: 0.1614\n",
      "Epoch 36/50\n",
      "339/339 [==============================] - 477s 1s/step - loss: 2.5803 - accuracy: 0.2826 - val_loss: 3.2869 - val_accuracy: 0.1566\n",
      "Epoch 37/50\n",
      "339/339 [==============================] - 474s 1s/step - loss: 2.5403 - accuracy: 0.2909 - val_loss: 3.3043 - val_accuracy: 0.1472\n",
      "Epoch 38/50\n",
      "339/339 [==============================] - 423s 1s/step - loss: 2.5347 - accuracy: 0.2892 - val_loss: 3.3278 - val_accuracy: 0.1598\n",
      "Epoch 39/50\n",
      "339/339 [==============================] - 431s 1s/step - loss: 2.5075 - accuracy: 0.2951 - val_loss: 3.3156 - val_accuracy: 0.1598\n",
      "Epoch 40/50\n",
      "339/339 [==============================] - 488s 1s/step - loss: 2.4843 - accuracy: 0.3055 - val_loss: 3.3308 - val_accuracy: 0.1614\n",
      "Epoch 41/50\n",
      "339/339 [==============================] - 435s 1s/step - loss: 2.4355 - accuracy: 0.3156 - val_loss: 3.3300 - val_accuracy: 0.1630\n",
      "Epoch 42/50\n",
      "339/339 [==============================] - 444s 1s/step - loss: 2.4136 - accuracy: 0.3208 - val_loss: 3.3188 - val_accuracy: 0.1677\n",
      "Epoch 43/50\n",
      "339/339 [==============================] - 474s 1s/step - loss: 2.3844 - accuracy: 0.3343 - val_loss: 3.3481 - val_accuracy: 0.1677\n",
      "Epoch 44/50\n",
      "339/339 [==============================] - 490s 1s/step - loss: 2.3919 - accuracy: 0.3272 - val_loss: 3.2898 - val_accuracy: 0.1677\n",
      "Epoch 45/50\n",
      "339/339 [==============================] - 439s 1s/step - loss: 2.3810 - accuracy: 0.3278 - val_loss: 3.3304 - val_accuracy: 0.1582\n",
      "Epoch 46/50\n",
      "339/339 [==============================] - 496s 1s/step - loss: 2.3576 - accuracy: 0.3361 - val_loss: 3.3579 - val_accuracy: 0.1582\n",
      "Epoch 47/50\n",
      "339/339 [==============================] - 468s 1s/step - loss: 2.3156 - accuracy: 0.3448 - val_loss: 3.3701 - val_accuracy: 0.1867\n",
      "Epoch 48/50\n",
      "339/339 [==============================] - 496s 1s/step - loss: 2.3116 - accuracy: 0.3418 - val_loss: 3.3618 - val_accuracy: 0.1835\n",
      "Epoch 49/50\n",
      "339/339 [==============================] - 421s 1s/step - loss: 2.2683 - accuracy: 0.3555 - val_loss: 3.4103 - val_accuracy: 0.1677\n",
      "Epoch 50/50\n",
      "339/339 [==============================] - 454s 1s/step - loss: 2.2498 - accuracy: 0.3599 - val_loss: 3.3118 - val_accuracy: 0.1835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a211ebcbb0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=\"Adam\", loss='categorical_crossentropy', metrics='accuracy')\n",
    "model.fit_generator(generator=my_training_batch_generator, epochs = 50,validation_data = my_validation_batch_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460f9af9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6ab8e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f1c09d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69843fa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2649eb59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98506d66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7de704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549a501e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831105e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
